{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from dataset import FacialKeypointsDataset\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import config\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# constant paths\n",
    "ROOT_PATH = './'\n",
    "OUTPUT_PATH = './video'\n",
    "TEST_PATH = './outputs/Testing-images'\n",
    "# learning parameters\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.001\n",
    "EPOCHS = 30\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# train/test split\n",
    "TEST_SPLIT = 0.1\n",
    "# show dataset keypoint plot\n",
    "SHOW_DATASET_PLOT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pretrainedmodels\n",
    "\n",
    "class FaceKeypointResNet18(nn.Module):\n",
    "    def __init__(self, pretrained, requires_grad):\n",
    "        super(FaceKeypointResNet18, self).__init__()\n",
    "        if pretrained == True:\n",
    "            self.model = pretrainedmodels.__dict__['resnet18'](pretrained='imagenet')\n",
    "        else:\n",
    "            self.model = pretrainedmodels.__dict__['resnet18'](pretrained=None)\n",
    "        if requires_grad == True:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = True\n",
    "            print('Training intermediate layer parameters...')\n",
    "        elif requires_grad == False:\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            print('Freezing intermediate layer parameters...')\n",
    "        # change the final layer\n",
    "        self.l0 = nn.Linear(512, 136)\n",
    "    def forward(self, x):\n",
    "        # get the batch size only, ignore (c, h, w)\n",
    "        batch, _, _, _ = x.shape\n",
    "        x = self.model.features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch, -1)\n",
    "        l0 = self.l0(x)\n",
    "        return l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing intermediate layer parameters...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=FaceKeypointResNet18\n",
       "  (model): RecursiveScriptModule(\n",
       "    original_name=ResNet\n",
       "    (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "    (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "    (maxpool): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "    (layer1): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "      (1): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (layer2): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (downsample): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        )\n",
       "      )\n",
       "      (1): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (layer3): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (downsample): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        )\n",
       "      )\n",
       "      (1): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (layer4): RecursiveScriptModule(\n",
       "      original_name=Sequential\n",
       "      (0): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (downsample): RecursiveScriptModule(\n",
       "          original_name=Sequential\n",
       "          (0): RecursiveScriptModule(original_name=Conv2d)\n",
       "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        )\n",
       "      )\n",
       "      (1): RecursiveScriptModule(\n",
       "        original_name=BasicBlock\n",
       "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "        (relu): RecursiveScriptModule(original_name=ReLU)\n",
       "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "        (bn2): RecursiveScriptModule(original_name=BatchNorm2d)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): RecursiveScriptModule(original_name=AdaptiveAvgPool2d)\n",
       "    (last_linear): RecursiveScriptModule(original_name=Linear)\n",
       "  )\n",
       "  (l0): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FaceKeypointResNet18(pretrained=True, requires_grad=False).to(config.DEVICE)\n",
    "model = torch.load('./outputs/traced_model_18.pth', map_location='cpu')\n",
    "\n",
    "# Get the model state dictionary\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Filter out unnecessary keys\n",
    "# checkpoint = {k: v for k, v in checkpoint.items() if k in model_state_dict}\n",
    "\n",
    "# Load the modified checkpoint\n",
    "# model.load_state_dict(checkpoint, strict=False)\n",
    "model.eval()\n",
    "# model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mouth(image, lip , outputs):\n",
    "    max_x = 0\n",
    "    min_x = 0\n",
    "    max_y = 0\n",
    "    min_y = 0\n",
    "\n",
    "    for i, ind in enumerate(lip):\n",
    "        (x, y) = outputs[ind]\n",
    "        if i == 0:\n",
    "            max_x = x\n",
    "            min_x = x\n",
    "            max_y = y\n",
    "            min_y = y\n",
    "\n",
    "        if x > max_x:\n",
    "            max_x = x\n",
    "        if x < min_x:\n",
    "            min_x = x\n",
    "        if y > max_y:\n",
    "            max_y = y\n",
    "        if y < min_y:\n",
    "            min_y = y\n",
    "        \n",
    "    img_mouth_seg = image[ int(min_y-5) : int(max_y+10), int(min_x-10) : int(max_x+10), :]\n",
    "    # print(\"Hi Shape: \" , img_mouth_seg.shape , image.shape)\n",
    "    img_mouth_seg = img_mouth_seg[:,:,0:3]*255\n",
    "    \n",
    "    return img_mouth_seg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_emotion(img_mouth_segment, template_mouth_positive, template_mouth_negative):\n",
    "    img_mouth_segment = cv2.resize(img_mouth_segment, (40, 80))\n",
    "    img_mouth_segment = cv2.cvtColor(img_mouth_segment, cv2.COLOR_BGR2GRAY)\n",
    "    img_mouth_segment = img_mouth_segment.astype(np.uint8)\n",
    "    # print(img_mouth_segment)\n",
    "\n",
    "    # print(img_mouth_segment)\n",
    "    # print(template_mouth_positive)\n",
    "    \n",
    "    score_positive = cv2.matchTemplate(img_mouth_segment, template_mouth_positive, cv2.TM_CCOEFF_NORMED)[0][0]\n",
    "    score_negative = cv2.matchTemplate(img_mouth_segment, template_mouth_negative, cv2.TM_CCOEFF_NORMED)[0][0]\n",
    "\n",
    "\n",
    "    if score_negative  > score_positive:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    # # print(score_positive)\n",
    "    # # print(score_negative)\n",
    "    # diff = score_positive - score_negative\n",
    "    # # print(diff)\n",
    "\n",
    "    # if(diff > 0):\n",
    "    #     # print(\"Positive Emotion\")\n",
    "    #     return 1\n",
    "    # else:\n",
    "    #     # print(\"Negative Emotion\")\n",
    "    #     return 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_mouth_positive = cv2.imread('./Results/Task 1.3/Positive-lips.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "template_mouth_negative = cv2.imread('./Results/Task 1.3/Negative-lips.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "template_mouth_positive = cv2.resize(template_mouth_positive, (40, 80))\n",
    "template_mouth_negative = cv2.resize(template_mouth_negative, (40, 80))\n",
    "\n",
    "template_mouth_positive = template_mouth_positive.astype(np.uint8)\n",
    "template_mouth_negative = template_mouth_negative.astype(np.uint8)\n",
    "\n",
    "upper_lip = [48, 49, 50, 51, 52, 53, 54, 61, 62, 63]\n",
    "lower_lip = [55, 56, 57, 58, 59, 60, 64, 65, 66, 67]\n",
    "\n",
    "lip = []\n",
    "lip.extend(upper_lip)\n",
    "lip.extend(lower_lip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# capture the webcam\n",
    "cap = cv2.VideoCapture('./video/vid_02.mp4')\n",
    "if (cap.isOpened() == False):\n",
    "    print('Error while trying to open webcam. Plese check again...')\n",
    " \n",
    "# get the frame width and height\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "# set up the save file path\n",
    "save_path = f\"{config.OUTPUT_PATH}/vid_keypoint_detection_R18.mp4\"\n",
    "# define codec and create VideoWriter object \n",
    "out = cv2.VideoWriter(f\"{save_path}\", \n",
    "                      cv2.VideoWriter_fourcc(*'mp4v'), 30, \n",
    "                      (frame_width, frame_height))\n",
    "\n",
    "# Variables for FPS calculation\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "while(cap.isOpened()):\n",
    "#     print(\"Hi\")\n",
    "    # capture each frame of the video\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        with torch.no_grad():\n",
    "            # processing_start_time = time.time()\n",
    "            image = frame\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            orig_frame = image.copy()\n",
    "            orig_h, orig_w, c = orig_frame.shape\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = image / 255.0\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "            image = torch.tensor(image, dtype=torch.float)\n",
    "            image = image.unsqueeze(0).to(config.DEVICE)\n",
    "            # print(image.shape)\n",
    "            # processing_time = time.time() - processing_start_time\n",
    "            # print(\"Processing Time\" , processing_time)\n",
    "            # with torch.autocast(device_type = 'cuda' , dtype = torch.float16):\n",
    "                # model_start_time = time.time()\n",
    "                # outputs = model(image.half())\n",
    "                # model_time = time.time() - model_start_time\n",
    "            # print(\"Model Time\" , model_time)\n",
    "            \n",
    "            # print(\"Model Time\" , processing_time)\n",
    "            outputs = model(image)\n",
    "            \n",
    "            outputs = outputs.reshape(68, 2)\n",
    "            outputs = outputs.detach().cpu()\n",
    "            \n",
    "            img_mouth_seg = extract_mouth(frame, lip, outputs)\n",
    "            emotion = measure_emotion(img_mouth_seg, template_mouth_positive, template_mouth_negative)\n",
    "            if emotion == 1:\n",
    "                state = 'Positive'\n",
    "            else:\n",
    "                state = 'Negative'\n",
    "            # Calculate FPS\n",
    "        frame_count += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        fps = frame_count / elapsed_time\n",
    "\n",
    "        # Display the FPS on the frame\n",
    "        cv2.putText(orig_frame, f'FPS: {round(fps, 2)} {state}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "        # cv2.putText(orig_frame, f'FPS: {round(fps, 2)}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "        outputs = outputs.cpu().detach().numpy()\n",
    "        outputs = outputs.reshape(-1, 2)\n",
    "        keypoints = outputs\n",
    "        for p in range(keypoints.shape[0]):\n",
    "            cv2.circle(orig_frame, (int(keypoints[p, 0]), int(keypoints[p, 1])),\n",
    "                        1, (0, 0, 255), -1, cv2.LINE_AA)\n",
    "        orig_frame = cv2.resize(orig_frame, (frame_width, frame_height))\n",
    "        cv2.imshow('Facial Keypoint Frame', orig_frame)\n",
    "        out.write(orig_frame)\n",
    "        # press `q` to exit\n",
    "        if cv2.waitKey(27) & 0xFF == ord('q'):\n",
    "            break\n",
    " \n",
    "    else: \n",
    "        break\n",
    "        \n",
    "# release VideoCapture()\n",
    "cap.release()\n",
    "out.release()\n",
    "# close all frames and video windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd712ce7dc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAF7CAYAAABy0OkAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbv0lEQVR4nO3df2xd9X038M+1E19oSZymIXa8/GgCLawFMi0rmdWW0cYiyR8ICn9A20cKLQKVJn1Gs64j04CW7ZE7pod13VL4oxtppRY6pgFqpbG1oTHqmlAlJaJ0a0QidwlKHNZIsUMgTpT7ff5AeI8hxPG59vfca79e0pHie8/x9+Pv/V777ZNz/KmklFIAAGTSUnYBAMD0InwAAFkJHwBAVsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQ1YyyC3izWq0WBw8ejFmzZkWlUim7HADgHKSU4tixY9HV1RUtLWc/t9Fw4ePgwYOxaNGisssAAAo4cOBALFy48Kz7NFz4mDVrVkREXP+/7oiZbdVxH+9sSWOqjJGCaTK1mYUPLeMtWs/3haLH1jVmFDt2rN82z6a1tbXwsUXVU++MGcV+fM2YWfzH3ozW4sfOnFnsPVPPHJ0q+CO+paXY+hs+8Vr83f/53yM/x8+m4cLHG2/YmW1V4WMKqecNRAOqK3zkf482XfgoeKzwMbaiIaCeMesZt545aikcPur7fn0u63fSfiJs3rw53vOe98R5550XK1eujJ/97GeTNRQA0EQmJXx873vfi40bN8a9994bP//5z2P58uWxevXqePnllydjOACgiUxK+HjggQfitttui09/+tPx/ve/Px566KF4xzveEf/wD/8wGcMBAE1kwsPHyZMnY9euXdHT0/M/g7S0RE9PT2zfvv0t+w8PD8fQ0NCoDQCYuiY8fPzmN7+J06dPR0dHx6jHOzo6YmBg4C379/b2Rnt7+8jmNlsAmNpKvwVh06ZNMTg4OLIdOHCg7JIAgEk04bfazps3L1pbW+Pw4cOjHj98+HB0dna+Zf9qtRrV6vhvqQUAmtOEn/loa2uLFStWxNatW0ceq9VqsXXr1uju7p7o4QCAJjMpf2Rs48aNsW7duvi93/u9uPLKK+NrX/taHD9+PD796U9PxnAAQBOZlPBx0003xX//93/HPffcEwMDA/E7v/M78dRTT73lIlQAYPqZtD+vvmHDhtiwYcNkfXoAoEk1XG+XN1QqFX1aoEGV9d5spj4r9YypFxJTnRUOAGQlfAAAWQkfAEBWwgcAkJXwAQBkJXwAAFkJHwBAVsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQlfABAGTVsF1tozLj9Y0pIYUOxVNJKmncoquontVXxphlaLZ6a5mPK/PYqciZDwAgK+EDAMhK+AAAshI+AICshA8AICvhAwDISvgAALISPgCArIQPACAr4QMAyEr4AACyEj4AgKyEDwAgK+EDAMiqcXvWVypRqTRbk2fejtdyqinn9Sy6jupZf0WPbWnJ/7tdGV9nPcqYIxqDVx4AyEr4AACyEj4AgKyEDwAgK+EDAMhK+AAAshI+AICshA8AICvhAwDISvgAALISPgCArIQPACAr4QMAyKpxu9qmyuvbOOme2pgqJXVBZZKU9D4ro6vtdGGOyMmZDwAgK+EDAMhK+AAAshI+AICshA8AICvhAwDISvgAALISPgCArIQPACAr4QMAyEr4AACyEj4AgKyEDwAgK+EDAMhqRtkFvJ1KpVKoxbO20I3J6zLVlPN6Fl1HLS35f88qY817n9EsnPkAALISPgCArIQPACCrCQ8fX/7yl0eu13hju/TSSyd6GACgSU3KBacf+MAH4kc/+tH/DDKjYa9rBQAym5RUMGPGjOjs7JyMTw0ANLlJuebjxRdfjK6urli2bFl86lOfiv3797/tvsPDwzE0NDRqAwCmrgkPHytXrowtW7bEU089FQ8++GD09/fHRz7ykTh27NgZ9+/t7Y329vaRbdGiRRNdEgDQQCoppTSZAxw9ejSWLFkSDzzwQNx6661veX54eDiGh4dHPh4aGopFixbFTbfdFW1t1XGP54/sNCavy1RTzo1y/sjY5I3Z2to6gZWcm3pel6LHzpw5s/CY9Vy/WHTceubodMErK4qOOXzi1fi/d98Wg4ODMXv27LPuO+lXgs6ZMyfe9773xd69e8/4fLVajWp1/CEDAGhOk/7rwCuvvBL79u2LBQsWTPZQAEATmPDw8cUvfjH6+vri17/+dfz0pz+Nj3/849Ha2hqf+MQnJnooAKAJTfh/u7z00kvxiU98Io4cORIXXnhhfPjDH44dO3bEhRdeONFDAQBNaMLDx6OPPjrRnxIAmEIa9k+PVirFrtx2VwVMvlodx9bzHp3UW/MmWBnfieoZc7p856xn7dZz7OmCN5bWdUNqwRe1Viv2ldZq516rxnIAQFbCBwCQlfABAGQlfAAAWQkfAEBWwgcAkJXwAQBkJXwAAFkJHwBAVsIHAJCV8AEAZCV8AABZCR8AQFYN29UWACZa0Y6tEfV1mC16bD1jNnKTd2c+AICshA8AICvhAwDISvgAALISPgCArIQPACAr4QMAyEr4AACyEj4AgKyEDwAgK+EDAMhK+AAAshI+AICshA8AIKsZZRfw9lqiWDZq4B7CAIAzHwBAXsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQlfABAGQlfAAAWQkfAEBWwgcAkJXwAQBkJXwAAFkJHwBAVsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQlfABAGQlfAAAWQkfAEBWwgcAkJXwAQBkJXwAAFkJHwBAVsIHAJCV8AEAZCV8AABZzSi7gLdTqVSiUqmUXQZwBrU63pqlvK1LGLOMr7OeMZvudSl4bD1fZz3rvvCxdYzZWvzQSefMBwCQlfABAGQlfAAAWY07fDzzzDNx7bXXRldXV1QqlXjiiSdGPZ9SinvuuScWLFgQ559/fvT09MSLL744UfUCAE1u3OHj+PHjsXz58ti8efMZn7///vvj61//ejz00EPx7LPPxjvf+c5YvXp1nDhxou5iAYDmN+67XdauXRtr164943Mppfja174Wf/ZnfxbXXXddRER8+9vfjo6OjnjiiSfi5ptvrq9aAKDpTeg1H/39/TEwMBA9PT0jj7W3t8fKlStj+/btZzxmeHg4hoaGRm0AwNQ1oeFjYGAgIiI6OjpGPd7R0THy3Jv19vZGe3v7yLZo0aKJLAkAaDCl3+2yadOmGBwcHNkOHDhQdkkAwCSa0PDR2dkZERGHDx8e9fjhw4dHnnuzarUas2fPHrUBAFPXhIaPpUuXRmdnZ2zdunXksaGhoXj22Weju7t7IocCAJrUuO92eeWVV2Lv3r0jH/f398fu3btj7ty5sXjx4rjzzjvjL/7iL+K9731vLF26NO6+++7o6uqK66+/fiLrBgCa1LjDx86dO+OjH/3oyMcbN26MiIh169bFli1b4ktf+lIcP348br/99jh69Gh8+MMfjqeeeirOO++8iasaAGha4w4fV199daSU3vb5SqUS9913X9x33311FQYATE3jDh8AlTr6kre05L/Jrp56p8uYzfa6lDG/TJzSb7UFAKYX4QMAyEr4AACyEj4AgKyEDwAgK+EDAMhK+AAAshI+AICshA8AICvhAwDISvgAALISPgCArIQPACCrxu1qm1pe34CG01JpLXxsJUro9mrMsdXx/bZwh9lUeMji9dbzc6WMY+sZs4Eb//rpDgBkJXwAAFkJHwBAVsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQlfABAGQlfAAAWQkfAEBWwgcAkJXwAQBkJXwAAFnNKLsAgHNVuHW7MeGctbQUOy/R0nLu69aZDwAgK+EDAMhK+AAAshI+AICshA8AICvhAwDISvgAALISPgCArIQPACAr4QMAyEr4AACyEj4AgKyEDwAgq4btapsqKVJLKrsMGJei3SAjincyTZXWwmOmVPA9VvQ4JlWzdcNttnrrkop9rZV6zhGkgsdmOM6ZDwAgK+EDAMhK+AAAshI+AICshA8AICvhAwDISvgAALISPgCArIQPACAr4QMAyEr4AACyEj4AgKyEDwAgK+EDAMhqRtkFAOWZVi3NoU4ppcLH1mq1Qse1trYWHrNovUVrHc9xznwAAFkJHwBAVsIHAJDVuMPHM888E9dee210dXVFpVKJJ554YtTzt9xyS1QqlVHbmjVrJqpeAKDJjTt8HD9+PJYvXx6bN29+233WrFkThw4dGtkeeeSRuooEAKaOcd/tsnbt2li7du1Z96lWq9HZ2Vm4KABg6pqUaz62bdsW8+fPj0suuSTuuOOOOHLkyNvuOzw8HENDQ6M2AGDqmvDwsWbNmvj2t78dW7dujb/8y7+Mvr6+WLt2bZw+ffqM+/f29kZ7e/vItmjRookuCQBoIBP+R8ZuvvnmkX9ffvnlccUVV8RFF10U27Zti1WrVr1l/02bNsXGjRtHPh4aGhJAAGAKm/RbbZctWxbz5s2LvXv3nvH5arUas2fPHrUBAFPXpIePl156KY4cORILFiyY7KEAgCYw7v92eeWVV0adxejv74/du3fH3LlzY+7cufGVr3wlbrzxxujs7Ix9+/bFl770pbj44otj9erVE1o4ANCcxh0+du7cGR/96EdHPn7jeo1169bFgw8+GM8//3x861vfiqNHj0ZXV1dcc8018ed//udRrVYnrmoAoGmNO3xcffXVZ+2U96//+q91FQQATG0TfrfLxGmJSFrP0GTqWLNFu3WnluJtvpk8lUql7BJoJAW/N6Ra8XVUfA0WPC6d+3F+ugMAWQkfAEBWwgcAkJXwAQBkJXwAAFkJHwBAVsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQlfABAGQlfAAAWTVwV1toPrVarfCxLS0Fu14WbYdbBx1bmQj1rF1rcGy5vzeMZzxnPgCArIQPACAr4QMAyEr4AACyEj4AgKyEDwAgK+EDAMhK+AAAshI+AICshA8AICvhAwDISvgAALISPgCArIQPACCrGWUXALyuVqsVO7CldWILOQf1dOqupxV60XHra79e7Ngy5qieMWt1HNzSUqzeutZCwbdLPU3mi44ZEZFaio08njb1b1Z0eouOOZ7jnPkAALISPgCArIQPACAr4QMAyEr4AACyEj4AgKyEDwAgK+EDAMhK+AAAshI+AICshA8AICvhAwDISvgAALISPgCArGaUXQBQn1qtjj7fBbW0FP+9pb4W4UVbzdfTSL2YutrFF6y3njHLUMZaKEsZa7CR15EzHwBAVsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQlfABAGQlfAAAWQkfAEBWwgcAkJXwAQBkJXwAAFkJHwBAVo3b1TZVXt+AsyvhbVJPJ90yOuKW0WF2Oim6HspYC/W8nnWthYJLsL71p6stAEBECB8AQGbCBwCQ1bjCR29vb3zwgx+MWbNmxfz58+P666+PPXv2jNrnxIkTsX79+nj3u98dF1xwQdx4441x+PDhCS0aAGhe4woffX19sX79+tixY0f88Ic/jFOnTsU111wTx48fH9nnC1/4Qnz/+9+Pxx57LPr6+uLgwYNxww03THjhAEBzGtfdLk899dSoj7ds2RLz58+PXbt2xVVXXRWDg4Px93//9/Hd7343Pvaxj0VExMMPPxy//du/HTt27Ijf//3fn7jKAYCmVNc1H4ODgxERMXfu3IiI2LVrV5w6dSp6enpG9rn00ktj8eLFsX379jN+juHh4RgaGhq1AQBTV+HwUavV4s4774wPfehDcdlll0VExMDAQLS1tcWcOXNG7dvR0REDAwNn/Dy9vb3R3t4+si1atKhoSQBAEygcPtavXx8vvPBCPProo3UVsGnTphgcHBzZDhw4UNfnAwAaW6G/cLphw4b4wQ9+EM8880wsXLhw5PHOzs44efJkHD16dNTZj8OHD0dnZ+cZP1e1Wo1qtVqkDACgCY3rzEdKKTZs2BCPP/54PP3007F06dJRz69YsSJmzpwZW7duHXlsz549sX///uju7p6YigGApjauMx/r16+P7373u/Hkk0/GrFmzRq7jaG9vj/PPPz/a29vj1ltvjY0bN8bcuXNj9uzZ8fnPfz66u7vd6QIARMQ4w8eDDz4YERFXX331qMcffvjhuOWWWyIi4q//+q+jpaUlbrzxxhgeHo7Vq1fHN77xjQkpFgBofuMKH+fSXe+8886LzZs3x+bNmwsXBQBMXYUuOM0hpaSVNZyLDO2vJ1LR9usRxVuw1/O9pGh78TLGbDbNthbqqrdSbNz6xsy7dsdzmMZyAEBWwgcAkJXwAQBkJXwAAFkJHwBAVsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQlfABAGQlfAAAWQkfAEBWutpCk0u1/L9DlNV1tXa62HFFO6BGjK9T5/+vnjkq/K2vntelhGPrWkep4Gta9LiISLU6XtOWop1i6+jCm4p3xC003jg68DrzAQBkJXwAAFkJHwBAVsIHAJCV8AEAZCV8AABZCR8AQFbCBwCQlfABAGQlfAAAWQkfAEBWwgcAkJXwAQBk1XBdbd/o4Hfq5HDJlUCTqLSWMGY5XW2LaqlMj86/9YxZxrH1jNnSUuzYejoc13Ns7XSxH7ctLcXf35WC5xeKfp0nh1+LiHPrxFtJDda3/qWXXopFixaVXQYAUMCBAwdi4cKFZ92n4cJHrVaLgwcPxqxZs86YioeGhmLRokVx4MCBmD17dgkVNj5zNDZzdHbmZ2zmaGzmaGxTaY5SSnHs2LHo6uoa8+xJw/23S0tLy5iJKSJi9uzZTf9CTTZzNDZzdHbmZ2zmaGzmaGxTZY7a29vPaT8XnAIAWQkfAEBWTRc+qtVq3HvvvVGtVssupWGZo7GZo7MzP2MzR2MzR2ObrnPUcBecAgBTW9Od+QAAmpvwAQBkJXwAAFkJHwBAVk0VPjZv3hzvec974rzzzouVK1fGz372s7JLahhf/vKXo1KpjNouvfTSsssq1TPPPBPXXnttdHV1RaVSiSeeeGLU8ymluOeee2LBggVx/vnnR09PT7z44ovlFFuSsebolltuecu6WrNmTTnFlqS3tzc++MEPxqxZs2L+/Plx/fXXx549e0btc+LEiVi/fn28+93vjgsuuCBuvPHGOHz4cEkV53cuc3T11Ve/ZS199rOfLani/B588MG44oorRv6YWHd3d/zLv/zLyPPTbQ01Tfj43ve+Fxs3box77703fv7zn8fy5ctj9erV8fLLL5ddWsP4wAc+EIcOHRrZfvKTn5RdUqmOHz8ey5cvj82bN5/x+fvvvz++/vWvx0MPPRTPPvtsvPOd74zVq1fHiRMnMldanrHmKCJizZo1o9bVI488krHC8vX19cX69etjx44d8cMf/jBOnToV11xzTRw/fnxkny984Qvx/e9/Px577LHo6+uLgwcPxg033FBi1XmdyxxFRNx2222j1tL9999fUsX5LVy4ML761a/Grl27YufOnfGxj30srrvuuvjlL38ZEdNwDaUmceWVV6b169ePfHz69OnU1dWVent7S6yqcdx7771p+fLlZZfRsCIiPf744yMf12q11NnZmf7qr/5q5LGjR4+marWaHnnkkRIqLN+b5yillNatW5euu+66UuppVC+//HKKiNTX15dSen3dzJw5Mz322GMj+/znf/5nioi0ffv2ssos1ZvnKKWU/uAP/iD94R/+YXlFNaB3vetd6Zvf/Oa0XENNcebj5MmTsWvXrujp6Rl5rKWlJXp6emL79u0lVtZYXnzxxejq6oply5bFpz71qdi/f3/ZJTWs/v7+GBgYGLWm2tvbY+XKldbUm2zbti3mz58fl1xySdxxxx1x5MiRsksq1eDgYEREzJ07NyIidu3aFadOnRq1li699NJYvHjxtF1Lb56jN3znO9+JefPmxWWXXRabNm2KV199tYzySnf69Ol49NFH4/jx49Hd3T0t11DDNZY7k9/85jdx+vTp6OjoGPV4R0dH/OpXvyqpqsaycuXK2LJlS1xyySVx6NCh+MpXvhIf+chH4oUXXohZs2aVXV7DGRgYiIg445p64zle/y+XG264IZYuXRr79u2LP/3TP421a9fG9u3bo7W1tezysqvVanHnnXfGhz70objssssi4vW11NbWFnPmzBm173RdS2eao4iIT37yk7FkyZLo6uqK559/Pv7kT/4k9uzZE//8z/9cYrV5/eIXv4ju7u44ceJEXHDBBfH444/H+9///ti9e/e0W0NNET4Y29q1a0f+fcUVV8TKlStjyZIl8Y//+I9x6623llgZzezmm28e+ffll18eV1xxRVx00UWxbdu2WLVqVYmVlWP9+vXxwgsvTPvrqc7m7ebo9ttvH/n35ZdfHgsWLIhVq1bFvn374qKLLspdZikuueSS2L17dwwODsY//dM/xbp166Kvr6/sskrRFP/tMm/evGhtbX3Llb+HDx+Ozs7OkqpqbHPmzIn3ve99sXfv3rJLaUhvrBtranyWLVsW8+bNm5brasOGDfGDH/wgfvzjH8fChQtHHu/s7IyTJ0/G0aNHR+0/HdfS283RmaxcuTIiYlqtpba2trj44otjxYoV0dvbG8uXL4+/+Zu/mZZrqCnCR1tbW6xYsSK2bt068litVoutW7dGd3d3iZU1rldeeSX27dsXCxYsKLuUhrR06dLo7OwctaaGhobi2WeftabO4qWXXoojR45Mq3WVUooNGzbE448/Hk8//XQsXbp01PMrVqyImTNnjlpLe/bsif3790+btTTWHJ3J7t27IyKm1Vp6s1qtFsPDw9NzDZV9xeu5evTRR1O1Wk1btmxJ//Ef/5Fuv/32NGfOnDQwMFB2aQ3hj/7oj9K2bdtSf39/+vd///fU09OT5s2bl15++eWySyvNsWPH0nPPPZeee+65FBHpgQceSM8991z6r//6r5RSSl/96lfTnDlz0pNPPpmef/75dN1116WlS5em1157reTK8znbHB07dix98YtfTNu3b0/9/f3pRz/6Ufrd3/3d9N73vjedOHGi7NKzueOOO1J7e3vatm1bOnTo0Mj26quvjuzz2c9+Ni1evDg9/fTTaefOnam7uzt1d3eXWHVeY83R3r1703333Zd27tyZ+vv705NPPpmWLVuWrrrqqpIrz+euu+5KfX19qb+/Pz3//PPprrvuSpVKJf3bv/1bSmn6raGmCR8ppfS3f/u3afHixamtrS1deeWVaceOHWWX1DBuuummtGDBgtTW1pZ+67d+K910001p7969ZZdVqh//+McpIt6yrVu3LqX0+u22d999d+ro6EjVajWtWrUq7dmzp9yiMzvbHL366qvpmmuuSRdeeGGaOXNmWrJkSbrtttumXeA/0/xERHr44YdH9nnttdfS5z73ufSud70rveMd70gf//jH06FDh8orOrOx5mj//v3pqquuSnPnzk3VajVdfPHF6Y//+I/T4OBguYVn9JnPfCYtWbIktbW1pQsvvDCtWrVqJHikNP3WUCWllPKdZwEAprumuOYDAJg6hA8AICvhAwDISvgAALISPgCArIQPACAr4QMAyEr4AACyEj4AgKyEDwAgK+EDAMhK+AAAsvp/fZMwYTk5SKAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_mouth_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing intermediate layer parameters...\n"
     ]
    }
   ],
   "source": [
    "import torch.quantization\n",
    "\n",
    "# Load your trained model\n",
    "model = FaceKeypointResNet18(pretrained=True, requires_grad=False).to(config.DEVICE)\n",
    "checkpoint = torch.load('./outputs/model_18.pth', map_location='cpu')\n",
    "\n",
    "# Get the model state dictionary\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Filter out unnecessary keys\n",
    "checkpoint = {k: v for k, v in checkpoint.items() if k in model_state_dict}\n",
    "\n",
    "# Load the modified checkpoint\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "# model.eval()\n",
    "# model.half()\n",
    "\n",
    "# model_op = model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Quantize the model\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Conv2d}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# Save the quantized model\n",
    "torch.save(model.state_dict(), f\"{OUTPUT_PATH}/q_model_18.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing intermediate layer parameters...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FaceKeypointResNet18(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): None\n",
       "    (last_linear): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (l0): Linear(in_features=512, out_features=136, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your trained model\n",
    "model = FaceKeypointResNet18(pretrained=True, requires_grad=False).to(config.DEVICE)\n",
    "checkpoint = torch.load('./outputs/model_18.pth', map_location='cpu')\n",
    "\n",
    "# Get the model state dictionary\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Filter out unnecessary keys\n",
    "checkpoint = {k: v for k, v in checkpoint.items() if k in model_state_dict}\n",
    "\n",
    "# Load the modified checkpoint\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "model.half()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input = torch.rand(1,3,224,224).to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "\n",
    "traced_model_path = f'{OUTPUT_PATH}/traced_model_18.pth'\n",
    "\n",
    "traced_model.save(traced_model_path)\n",
    "\n",
    "# num_params = model.parameters()\n",
    "# print(f\"Number of Params: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV701",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
